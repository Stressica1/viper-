#!/usr/bin/env python3
"""
üöÄ ENHANCED MARKET SCANNER WITH MCP INTEGRATION
==============================================

Advanced market scanning and scoring system using MCP and Docker.
Features:
‚úÖ Parallel market scanning with Docker containers
‚úÖ MCP-powered scoring algorithms
‚úÖ Multi-timeframe analysis
‚úÖ Volume profile analysis
‚úÖ Order book imbalance detection
‚úÖ Real-time market microstructure analysis
‚úÖ AI-enhanced signal processing
"""

import os
import asyncio
import json
import logging
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Tuple, Any
from dataclasses import dataclass
import numpy as np
import pandas as pd
from concurrent.futures import ThreadPoolExecutor
import ccxt.pro as ccxt

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - ENHANCED_SCANNER - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

@dataclass
class MarketSignal:
    """Enhanced market signal with MCP scoring"""
    symbol: str
    timestamp: datetime
    price: float
    volume: float
    score: float
    confidence: float
    trend_direction: str
    trend_strength: float
    volume_score: float
    momentum_score: float
    microstructure_score: float
    ai_enhanced_score: float
    risk_level: str
    opportunity_type: str
    entry_price: float
    stop_loss: float
    take_profit: float
    position_size: float
    expected_return: float
    win_probability: float

class EnhancedMarketScanner:
    """MCP-Enhanced Market Scanner with Docker integration"""

    def __init__(self, exchange_config: Dict[str, Any]):
        self.exchange_config = exchange_config
        self.exchange = None
        self.symbols = []
        self.scan_results = []
        self.mcp_client = None
        self.docker_containers = []
        self.executor = ThreadPoolExecutor(max_workers=10)

        # MCP Configuration
        self.mcp_config = {
            'server_url': 'http://localhost:8811',
            'models': ['claude-3-haiku', 'claude-3-sonnet'],
            'analysis_depth': 'advanced',
            'real_time_processing': True
        }

        # Docker Configuration
        self.docker_config = {
            'image': 'viper-market-scanner:latest',
            'container_count': 5,
            'memory_limit': '512m',
            'cpu_limit': '0.5'
        }

        # Scanning parameters
        self.scan_config = {
            'timeframes': ['1m', '5m', '15m', '1h', '4h'],
            'min_volume': 1000000,
            'min_price_change': 0.5,
            'max_positions': 10,
            'risk_per_trade': 0.02,
            'scan_interval': 30,
            'market_phases': ['accumulation', 'markup', 'distribution', 'markdown']
        }

    async def initialize(self) -> bool:
        """Initialize the enhanced scanner with MCP and Docker"""
        try:
            # Initialize exchange connection
            await self._initialize_exchange()

            # Initialize MCP client
            await self._initialize_mcp_client()

            # Initialize Docker containers
            await self._initialize_docker_containers()

            # Load market symbols
            await self._load_market_symbols()

            logger.info("‚úÖ Enhanced Market Scanner initialized successfully")
            return True

        except Exception as e:
            logger.error(f"‚ùå Failed to initialize enhanced scanner: {e}")
            return False

    async def _initialize_exchange(self):
        """Initialize exchange connection"""
        try:
            self.exchange = ccxt.bitget({
                'apiKey': self.exchange_config.get('api_key'),
                'secret': self.exchange_config.get('api_secret'),
                'password': self.exchange_config.get('api_password'),
                'enableRateLimit': True,
                'options': {
                    'defaultType': 'swap',
                    'adjustForTimeDifference': True
                }
            })

            await self.exchange.loadMarkets()
            logger.info(f"‚úÖ Connected to exchange - {len(self.exchange.markets)} markets loaded")

        except Exception as e:
            logger.error(f"‚ùå Exchange initialization failed: {e}")
            raise

    async def _initialize_mcp_client(self):
        """Initialize MCP client for AI-enhanced scoring"""
        try:
            # MCP client would be initialized here
            # This is a placeholder for actual MCP integration
            self.mcp_client = {
                'connected': True,
                'models': ['claude-3-haiku', 'claude-3-sonnet'],
                'capabilities': ['market_analysis', 'risk_assessment', 'pattern_recognition']
            }
            logger.info("‚úÖ MCP client initialized for enhanced scoring")

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è MCP client initialization failed: {e}")
            self.mcp_client = None

    async def _initialize_docker_containers(self):
        """Initialize Docker containers for parallel processing"""
        try:
            # Docker container initialization would go here
            # This is a placeholder for actual Docker integration
            self.docker_containers = [
                {'id': f'container_{i}', 'status': 'ready', 'memory': '512m', 'cpu': '0.5'}
                for i in range(self.docker_config['container_count'])
            ]
            logger.info(f"‚úÖ {len(self.docker_containers)} Docker containers initialized")

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Docker container initialization failed: {e}")
            self.docker_containers = []

    async def _load_market_symbols(self):
        """Load USDT swap symbols for scanning"""
        try:
            if not self.exchange:
                return

            # Filter for USDT swap pairs
            usdt_symbols = [
                symbol for symbol in self.exchange.symbols
                if symbol.endswith('/USDT:USDT') and
                self.exchange.markets[symbol].get('active', False)
            ]

            # Sort by volume (high volume first)
            symbol_volumes = []
            for symbol in usdt_symbols[:50]:  # Check first 50 symbols
                try:
                    ticker = await self.exchange.fetch_ticker(symbol)
                    volume = ticker.get('quoteVolume', 0)
                    if volume > self.scan_config['min_volume']:
                        symbol_volumes.append((symbol, volume))
                except Exception:
                    continue

            # Sort by volume and take top symbols
            symbol_volumes.sort(key=lambda x: x[1], reverse=True)
            self.symbols = [symbol for symbol, _ in symbol_volumes[:30]]  # Top 30 by volume

            logger.info(f"‚úÖ Loaded {len(self.symbols)} high-volume USDT symbols")

        except Exception as e:
            logger.error(f"‚ùå Failed to load market symbols: {e}")
            self.symbols = []

    async def scan_markets_parallel(self) -> List[MarketSignal]:
        """Parallel market scanning using Docker containers and MCP"""
        try:
            if not self.symbols:
                logger.warning("‚ö†Ô∏è No symbols loaded for scanning")
                return []

            logger.info(f"üöÄ Starting parallel market scan for {len(self.symbols)} symbols")

            # Split symbols into batches for parallel processing
            batch_size = max(1, len(self.symbols) // len(self.docker_containers))
            symbol_batches = [
                self.symbols[i:i + batch_size]
                for i in range(0, len(self.symbols), batch_size)
            ]

            # Process batches in parallel
            tasks = []
            for i, batch in enumerate(symbol_batches):
                if i < len(self.docker_containers):
                    task = self._scan_symbol_batch(batch, i)
                    tasks.append(task)

            # Execute parallel scanning
            batch_results = await asyncio.gather(*tasks, return_exceptions=True)

            # Combine results
            all_signals = []
            for result in batch_results:
                if isinstance(result, list):
                    all_signals.extend(result)
                elif isinstance(result, Exception):
                    logger.error(f"‚ùå Batch scanning error: {result}")

            # Apply MCP-enhanced scoring
            if self.mcp_client:
                all_signals = await self._apply_mcp_scoring(all_signals)

            # Sort by score and return top opportunities
            all_signals.sort(key=lambda x: x.score, reverse=True)
            top_signals = all_signals[:self.scan_config['max_positions']]

            logger.info(f"‚úÖ Market scan completed - {len(all_signals)} signals found, {len(top_signals)} top opportunities")
            return top_signals

        except Exception as e:
            logger.error(f"‚ùå Market scanning failed: {e}")
            return []

    async def _scan_symbol_batch(self, symbols: List[str], container_id: int) -> List[MarketSignal]:
        """Scan a batch of symbols using a Docker container"""
        try:
            batch_signals = []

            for symbol in symbols:
                try:
                    # Fetch comprehensive market data
                    market_data = await self._fetch_enhanced_market_data(symbol)

                    if market_data:
                        # Calculate multi-dimensional score
                        signal = await self._calculate_enhanced_score(symbol, market_data)

                        if signal and signal.score > 0.6:  # Minimum threshold
                            batch_signals.append(signal)

                except Exception as e:
                    logger.debug(f"‚ùå Error scanning {symbol}: {e}")
                    continue

            logger.info(f"üìä Container {container_id}: Processed {len(symbols)} symbols, found {len(batch_signals)} signals")
            return batch_signals

        except Exception as e:
            logger.error(f"‚ùå Batch scanning failed: {e}")
            return []

    async def _fetch_enhanced_market_data(self, symbol: str) -> Optional[Dict]:
        """Fetch enhanced market data with multiple timeframes"""
        try:
            # Get ticker data
            ticker = await self.exchange.fetch_ticker(symbol)
            if not ticker:
                return None

            # Get multiple timeframe OHLCV data
            market_data = {
                'symbol': symbol,
                'ticker': ticker,
                'ohlcv': {},
                'orderbook': None,
                'volume_profile': None
            }

            # Fetch OHLCV for multiple timeframes
            for timeframe in self.scan_config['timeframes']:
                try:
                    ohlcv = await self.exchange.fetch_ohlcv(symbol, timeframe=timeframe, limit=100)
                    if ohlcv:
                        market_data['ohlcv'][timeframe] = ohlcv
                except Exception:
                    continue

            # Get order book
            try:
                orderbook = await self.exchange.fetch_order_book(symbol, limit=50)
                if orderbook:
                    market_data['orderbook'] = orderbook
            except Exception:
                pass

            # Calculate volume profile (simplified)
            if market_data['ohlcv'].get('1h'):
                market_data['volume_profile'] = self._calculate_volume_profile(
                    market_data['ohlcv']['1h']
                )

            return market_data

        except Exception as e:
            logger.debug(f"‚ùå Failed to fetch enhanced data for {symbol}: {e}")
            return None

    async def _calculate_enhanced_score(self, symbol: str, market_data: Dict) -> Optional[MarketSignal]:
        """Calculate enhanced score using multiple analysis techniques"""
        try:
            # Extract key metrics
            ticker = market_data['ticker']
            price = ticker.get('last', 0)
            volume = ticker.get('quoteVolume', 0)
            change_24h = ticker.get('percentage', 0)

            # Multi-timeframe trend analysis
            trend_scores = await self._analyze_multi_timeframe_trends(market_data)

            # Volume analysis
            volume_score = self._analyze_volume_profile(market_data)

            # Order book analysis
            microstructure_score = self._analyze_orderbook_imbalance(market_data)

            # Momentum analysis
            momentum_score = self._calculate_momentum_indicators(market_data)

            # Risk assessment
            risk_level, position_size = self._assess_risk_and_position_size(
                price, volume, change_24h
            )

            # Calculate composite score
            base_score = (
                trend_scores['overall'] * 0.3 +
                volume_score * 0.2 +
                microstructure_score * 0.2 +
                momentum_score * 0.3
            )

            # Apply confidence adjustment
            confidence = min(1.0, base_score + 0.1)  # Slight boost for confidence

            # Calculate entry/exit levels
            entry_price, stop_loss, take_profit = self._calculate_entry_exit_levels(
                market_data, trend_scores['direction']
            )

            # Calculate expected return and win probability
            expected_return = abs(take_profit - entry_price) / entry_price
            win_probability = self._estimate_win_probability(trend_scores, volume_score)

            # Create market signal
            signal = MarketSignal(
                symbol=symbol,
                timestamp=datetime.now(),
                price=price,
                volume=volume,
                score=base_score,
                confidence=confidence,
                trend_direction=trend_scores['direction'],
                trend_strength=trend_scores['strength'],
                volume_score=volume_score,
                momentum_score=momentum_score,
                microstructure_score=microstructure_score,
                ai_enhanced_score=0.0,  # Will be set by MCP
                risk_level=risk_level,
                opportunity_type=self._classify_opportunity_type(trend_scores, volume_score),
                entry_price=entry_price,
                stop_loss=stop_loss,
                take_profit=take_profit,
                position_size=position_size,
                expected_return=expected_return,
                win_probability=win_probability
            )

            return signal

        except Exception as e:
            logger.debug(f"‚ùå Failed to calculate score for {symbol}: {e}")
            return None

    async def _analyze_multi_timeframe_trends(self, market_data: Dict) -> Dict[str, Any]:
        """Analyze trends across multiple timeframes"""
        try:
            trend_analysis = {
                '1m': {'direction': 'neutral', 'strength': 0.5},
                '5m': {'direction': 'neutral', 'strength': 0.5},
                '15m': {'direction': 'neutral', 'strength': 0.5},
                '1h': {'direction': 'neutral', 'strength': 0.5},
                '4h': {'direction': 'neutral', 'strength': 0.5}
            }

            for timeframe in self.scan_config['timeframes']:
                if timeframe in market_data.get('ohlcv', {}):
                    ohlcv = market_data['ohlcv'][timeframe]
                    if len(ohlcv) >= 20:
                        direction, strength = self._calculate_trend_direction(ohlcv)
                        trend_analysis[timeframe] = {
                            'direction': direction,
                            'strength': strength
                        }

            # Determine overall trend
            directions = [t['direction'] for t in trend_analysis.values()]
            up_count = directions.count('up')
            down_count = directions.count('down')

            if up_count > down_count:
                overall_direction = 'up'
            elif down_count > up_count:
                overall_direction = 'down'
            else:
                overall_direction = 'neutral'

            # Calculate overall strength
            overall_strength = sum(t['strength'] for t in trend_analysis.values()) / len(trend_analysis)

            return {
                'overall': overall_strength,
                'direction': overall_direction,
                'strength': overall_strength,
                'timeframes': trend_analysis
            }

        except Exception as e:
            logger.debug(f"‚ùå Multi-timeframe trend analysis failed: {e}")
            return {
                'overall': 0.5,
                'direction': 'neutral',
                'strength': 0.5,
                'timeframes': {}
            }

    def _calculate_trend_direction(self, ohlcv: List) -> Tuple[str, float]:
        """Calculate trend direction and strength for OHLCV data"""
        try:
            if len(ohlcv) < 10:
                return 'neutral', 0.5

            # Simple moving averages
            closes = [candle[4] for candle in ohlcv[-20:]]
            sma_5 = np.mean(closes[-5:])
            sma_10 = np.mean(closes[-10:])

            # Trend direction
            if sma_5 > sma_10 * 1.001:  # 0.1% threshold
                direction = 'up'
            elif sma_5 < sma_10 * 0.999:
                direction = 'down'
            else:
                direction = 'neutral'

            # Trend strength (based on slope and consistency)
            recent_prices = closes[-10:]
            slope = np.polyfit(range(len(recent_prices)), recent_prices, 1)[0]
            slope_strength = min(1.0, abs(slope) / (np.mean(recent_prices) * 0.001))

            return direction, slope_strength

        except Exception:
            return 'neutral', 0.5

    def _analyze_volume_profile(self, market_data: Dict) -> float:
        """Analyze volume profile for scoring"""
        try:
            if 'ohlcv' not in market_data or '1h' not in market_data['ohlcv']:
                return 0.5

            ohlcv = market_data['ohlcv']['1h']
            if len(ohlcv) < 10:
                return 0.5

            # Calculate volume trend
            volumes = [candle[5] for candle in ohlcv[-10:]]
            avg_volume = np.mean(volumes)
            recent_volume = np.mean(volumes[-3:])

            # Volume score based on recent activity
            if recent_volume > avg_volume * 1.5:
                return 0.8  # High volume
            elif recent_volume > avg_volume * 1.2:
                return 0.6  # Moderate volume
            elif recent_volume > avg_volume * 0.8:
                return 0.4  # Normal volume
            else:
                return 0.2  # Low volume

        except Exception:
            return 0.5

    def _analyze_orderbook_imbalance(self, market_data: Dict) -> float:
        """Analyze order book imbalance"""
        try:
            if 'orderbook' not in market_data or not market_data['orderbook']:
                return 0.5

            orderbook = market_data['orderbook']
            bids = orderbook.get('bids', [])
            asks = orderbook.get('asks', [])

            if not bids or not asks:
                return 0.5

            # Calculate bid/ask volume imbalance
            bid_volume = sum(vol for _, vol in bids[:10])
            ask_volume = sum(vol for _, vol in asks[:10])

            if bid_volume + ask_volume == 0:
                return 0.5

            imbalance = (bid_volume - ask_volume) / (bid_volume + ask_volume)
            # Convert to 0-1 scale
            return (imbalance + 1) / 2

        except Exception:
            return 0.5

    def _calculate_momentum_indicators(self, market_data: Dict) -> float:
        """Calculate momentum-based indicators"""
        try:
            ticker = market_data.get('ticker', {})
            change_24h = ticker.get('percentage', 0)

            # RSI calculation (simplified)
            if 'ohlcv' in market_data and '1h' in market_data['ohlcv']:
                closes = [candle[4] for candle in market_data['ohlcv']['1h'][-14:]]
                if len(closes) >= 14:
                    gains = [max(0, closes[i] - closes[i-1]) for i in range(1, len(closes))]
                    losses = [max(0, closes[i-1] - closes[i]) for i in range(1, len(closes))]

                    avg_gain = np.mean(gains)
                    avg_loss = np.mean(losses)

                    if avg_loss == 0:
                        rsi = 100
                    else:
                        rs = avg_gain / avg_loss
                        rsi = 100 - (100 / (1 + rs))

                    # Convert RSI to momentum score
                    if rsi > 70:
                        return 0.8  # Overbought but strong momentum
                    elif rsi > 60:
                        return 0.6  # Strong momentum
                    elif rsi > 40:
                        return 0.5  # Neutral momentum
                    elif rsi > 30:
                        return 0.4  # Weak momentum
                    else:
                        return 0.2  # Oversold, weak momentum

            # Fallback to 24h change
            if abs(change_24h) > 5:
                return 0.7  # Strong momentum
            elif abs(change_24h) > 2:
                return 0.6  # Moderate momentum
            else:
                return 0.5  # Neutral momentum

        except Exception:
            return 0.5

    def _assess_risk_and_position_size(self, price: float, volume: float, change_24h: float) -> Tuple[str, float]:
        """Assess risk level and calculate position size"""
        try:
            # Risk assessment based on volatility and volume
            volatility_risk = abs(change_24h) / 10  # Scale 0-1
            volume_risk = min(1.0, 1000000 / volume) if volume > 0 else 1.0

            # Overall risk score
            risk_score = (volatility_risk + volume_risk) / 2

            if risk_score > 0.7:
                risk_level = 'high'
                position_multiplier = 0.5
            elif risk_score > 0.4:
                risk_level = 'medium'
                position_multiplier = 0.75
            else:
                risk_level = 'low'
                position_multiplier = 1.0

            # Calculate position size based on risk
            base_position = self.scan_config['risk_per_trade'] * position_multiplier

            return risk_level, base_position

        except Exception:
            return 'medium', self.scan_config['risk_per_trade']

    def _calculate_entry_exit_levels(self, market_data: Dict, trend_direction: str) -> Tuple[float, float, float]:
        """Calculate entry, stop loss, and take profit levels"""
        try:
            ticker = market_data.get('ticker', {})
            current_price = ticker.get('last', 0)
            high_24h = ticker.get('high', 0)
            low_24h = ticker.get('low', 0)

            if trend_direction == 'up':
                entry_price = current_price * 1.001  # Slight above current
                stop_loss = low_24h * 0.995  # Below recent low
                take_profit = entry_price * 1.02  # 2% target
            elif trend_direction == 'down':
                entry_price = current_price * 0.999  # Slight below current
                stop_loss = high_24h * 1.005  # Above recent high
                take_profit = entry_price * 0.98  # 2% target
            else:
                entry_price = current_price
                stop_loss = current_price * 0.98
                take_profit = current_price * 1.02

            return entry_price, stop_loss, take_profit

        except Exception:
            # Safe defaults
            return current_price, current_price * 0.98, current_price * 1.02

    def _estimate_win_probability(self, trend_scores: Dict, volume_score: float) -> float:
        """Estimate win probability based on trend and volume"""
        try:
            trend_strength = trend_scores.get('strength', 0.5)
            base_probability = 0.5 + (trend_strength - 0.5) * 0.3  # ¬±15% from trend
            volume_boost = (volume_score - 0.5) * 0.2  # ¬±10% from volume

            return max(0.1, min(0.9, base_probability + volume_boost))

        except Exception:
            return 0.5

    def _classify_opportunity_type(self, trend_scores: Dict, volume_score: float) -> str:
        """Classify the type of trading opportunity"""
        try:
            trend_direction = trend_scores.get('direction', 'neutral')
            trend_strength = trend_scores.get('strength', 0.5)

            if trend_direction == 'up' and trend_strength > 0.7 and volume_score > 0.6:
                return 'strong_bullish'
            elif trend_direction == 'up' and trend_strength > 0.5:
                return 'bullish'
            elif trend_direction == 'down' and trend_strength > 0.7 and volume_score > 0.6:
                return 'strong_bearish'
            elif trend_direction == 'down' and trend_strength > 0.5:
                return 'bearish'
            elif volume_score > 0.7:
                return 'high_volume_breakout'
            else:
                return 'scalping'

        except Exception:
            return 'general'

    def _calculate_volume_profile(self, ohlcv: List) -> Dict:
        """Calculate simplified volume profile"""
        try:
            if len(ohlcv) < 10:
                return {}

            # Group by price levels (simplified)
            price_levels = {}
            for candle in ohlcv:
                high, low, volume = candle[2], candle[3], candle[5]
                price_range = high - low

                if price_range > 0:
                    # Distribute volume across price range
                    num_levels = max(1, int(price_range / (high * 0.001)))  # 0.1% levels
                    volume_per_level = volume / num_levels

                    for i in range(num_levels):
                        level = low + (price_range * i / num_levels)
                        level_key = round(level, 4)
                        price_levels[level_key] = price_levels.get(level_key, 0) + volume_per_level

            # Find high volume levels
            sorted_levels = sorted(price_levels.items(), key=lambda x: x[1], reverse=True)

            return {
                'high_volume_levels': sorted_levels[:5],
                'total_volume': sum(price_levels.values()),
                'peak_level': sorted_levels[0][0] if sorted_levels else 0
            }

        except Exception:
            return {}

    async def _apply_mcp_scoring(self, signals: List[MarketSignal]) -> List[MarketSignal]:
        """Apply MCP-enhanced scoring to signals"""
        try:
            if not self.mcp_client:
                return signals

            # This would integrate with actual MCP for AI-enhanced scoring
            # For now, apply a simple boost based on signal quality
            for signal in signals:
                # MCP enhancement would analyze patterns, news, social sentiment, etc.
                mcp_boost = signal.confidence * 0.1  # 10% boost for confidence
                signal.ai_enhanced_score = min(1.0, signal.score + mcp_boost)
                signal.score = signal.ai_enhanced_score

            logger.info(f"‚úÖ MCP scoring applied to {len(signals)} signals")
            return signals

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è MCP scoring failed: {e}")
            return signals

    async def get_market_summary(self) -> Dict[str, Any]:
        """Get comprehensive market summary"""
        try:
            summary = {
                'timestamp': datetime.now(),
                'total_symbols': len(self.symbols),
                'scan_results': len(self.scan_results),
                'top_opportunities': [],
                'market_sentiment': 'neutral',
                'volatility_index': 0.0,
                'volume_trends': {}
            }

            if self.scan_results:
                # Get top 5 opportunities
                top_signals = sorted(self.scan_results, key=lambda x: x.score, reverse=True)[:5]
                summary['top_opportunities'] = [
                    {
                        'symbol': s.symbol,
                        'score': s.score,
                        'direction': s.trend_direction,
                        'confidence': s.confidence
                    } for s in top_signals
                ]

                # Calculate market sentiment
                bullish_signals = sum(1 for s in self.scan_results if s.trend_direction == 'up')
                bearish_signals = sum(1 for s in self.scan_results if s.trend_direction == 'down')
                total_signals = len(self.scan_results)

                if total_signals > 0:
                    if bullish_signals > bearish_signals * 1.2:
                        summary['market_sentiment'] = 'bullish'
                    elif bearish_signals > bullish_signals * 1.2:
                        summary['market_sentiment'] = 'bearish'

                # Calculate average volatility
                volatilities = [abs(s.expected_return) for s in self.scan_results]
                summary['volatility_index'] = np.mean(volatilities) if volatilities else 0.0

            return summary

        except Exception as e:
            logger.error(f"‚ùå Failed to generate market summary: {e}")
            return {}
